# NYC Fire Station Spatial-Temporal Analysis - CSE6242 Project

**Team:** Team 139

**Members:** Tyler, Vinuka, Harshitha, Rishi, Madeleine, Kevin

## Project Overview

This project analyzed NYC fire incidents using spatio-temporal data. Key objectives included predicting fire incident probability using wavelet features and optimizing potential new fire station locations using KDE and Genetic Algorithms. This repository contains the analysis code, notebooks, and an interactive Streamlit application to display results.

Application built with [Streamlit](https://docs.streamlit.io)

---

## Live Application Demo

The interactive dashboard is deployed on Render:

**➡️ [https://fire-station-spatial-temporal-analysis.onrender.com](https://fire-station-spatial-temporal-analysis.onrender.com)**

### Important Info [DO NOT SKIP THIS SECTION]

*Note: The free tier [Render](https://render.com) (AWS/GCP/Azure alternative) instance may take ~30-60 seconds to wake up if inactive. This ensures that we do not get charged, without having to set AWS Cloudwatch Alarms or a similar option on GCP/Azure.*

#### **If you simply want to use the deployed app, there is no need to continue below here, the rest is for local setup.**

---

## Running Locally

Follow these steps precisely to run the Streamlit application on your local machine.

**1. Prerequisites:**
   * Python 3.11 (Ensure it's in your system's PATH)
   * Pipenv (`pip install pipenv`)

**2. Setup Project:**
   ```bash
   git clone https://github.com/tyler-netek/fire-station-spatial-temporal-analysis-project.git
   cd fire-station-spatial-temporal-analysis-project
   pipenv install
   pipenv shell
   ```
   ---
   **NOTE for context of the commands we're using above:**
   
The `Pipfile` in the root of our repository specifies the main Python packages (i.e. `Streamlit`, `Pandas`, etc.) and the Python version this project requires so that all of the specified dependencies and their versions align to be used without conflict. Based on that, `pipenv` automatically generates the `Pipfile.lock` file, which records the exact versions of all installed libraries (including dependencies of dependencies), ensuring everyone builds the identical software environment both locally and for the Render deployment to use for our production application that is accessible at the URL earlier in this document.

Since the repository includes a `Pipfile.lock`, the command `pipenv install` simply installs the exact pre-defined package versions listed in the lock file into your local virual environment, guaranteeing reproducibility. After that, use `pipenv shell` to activate that specific environment so project commands i.e. `streamlit run app.py` use the correct dependencies. If `pipenv install` then `pipenv shell` were not used first, `streamlit run app.py` would not work as `streamlit` would not have yet been installed.

If for some reason there is still an issue with the library, we've provided error handling, and the interpreter will also complain and point out which library is missing. You can then manually do `pip install <missing library>`.

Also be sure that your virtual environment is using Python 3.11, because that is the only version that is guaranteed to have no dependency conflicts with all of the libraries and their specified versions.

---

**3. Offline Analysis Steps (Required for Full App Functionality):**
   The Streamlit app displays results generated by the following scripts/notebooks. Run these **before** launching the app locally. Execute commands from the project root directory within the virtual environment.
   * **Generate GA Results:**
      * Run: `python Optimization/Genetic_algo_final.py`
      * *Ensure this script is modified to save its output DataFrame to:* `Optimization/Data/optimal_ga_locations.csv` (This might potentially already exist, but putting here in case it doesn't.)
   * **Generate KDE/K-Medoids Results:**
      * Run the `Optimization/KDE+ New Fire Station Locations(K Medoids).ipynb` notebook (e.g., using `jupyter lab`).
      * *Verify paths inside the notebook. Ensure it reads required inputs (like PLUTO) and saves its outputs:* `Optimization/Data/Potential_location.csv` and `Optimization/Data/kde_by_zipcode.csv`. (Might already exist, please check.)
   * **Generate Prediction Output File:**
      * Run the `Prediction/Predict Fire Incidents.ipynb` notebook.
      * *Ensure it saves its output to:* `Prediction/Data/fire_incident_prediction_output.csv`.
   * **Generate Merged DNN Features File:**
      * Run the `Prediction/fire_incident_prediction_model_development.ipynb` notebook (at least partially).
      * *Ensure it saves the merged 'df' DataFrame to:* `Prediction/Data/merged_dnn_input_features.csv`.
   * **Exit Environment:** `exit`

**4. Run the Streamlit App:**
   ```bash
   streamlit run app.py
   ```
   * Access the application in your browser (usually `http://localhost:8501` by convention). You will see a message like the below in your terminal:

   ```
   You can now view your Streamlit app in your browser.

   Local URL: http://localhost:8501
   ```

---
